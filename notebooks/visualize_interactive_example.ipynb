{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d0f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43cbd3f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Mapping' from 'collections' (/mnt/projects/conda-envs/dgxenv-2024-11-27-08-23-26-x2139-centos9-py310-pt251cf/lib/python3.10/collections/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# set the right device\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# NOTE: assuming we are in `ca_body/notebooks`\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mattrdict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttrDict\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mth\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/projects/conda-envs/dgxenv-2024-11-27-08-23-26-x2139-centos9-py310-pt251cf/lib/python3.10/site-packages/attrdict/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mattrdict contains several mapping objects that allow access to their\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mkeys as attributes.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mattrdict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttrMap\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mattrdict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdictionary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttrDict\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mattrdict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefault\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttrDefault\n",
      "File \u001b[0;32m/mnt/projects/conda-envs/dgxenv-2024-11-27-08-23-26-x2139-centos9-py310-pt251cf/lib/python3.10/site-packages/attrdict/mapping.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mAn implementation of MutableAttr.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mapping\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mattrdict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixins\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MutableAttr\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Mapping' from 'collections' (/mnt/projects/conda-envs/dgxenv-2024-11-27-08-23-26-x2139-centos9-py310-pt251cf/lib/python3.10/collections/__init__.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# set the right device\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# NOTE: assuming we are in `ca_body/notebooks`\n",
    "sys.path.insert(0, '../')\n",
    "from attrdict import AttrDict\n",
    "\n",
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from ca_body.utils.module_loader import load_from_config\n",
    "from ca_body.utils.lbs import LBSModule\n",
    "from ca_body.utils.image import linear2displayBatch\n",
    "from ca_body.utils.geom_body import EulerXYZ_to_matrix\n",
    "\n",
    "from ca_body.utils.train import (\n",
    "    load_from_config,\n",
    "    load_checkpoint,\n",
    "    build_optimizer,\n",
    "    train,\n",
    ")\n",
    "from ca_body.utils.dataloader import BodyDataset, worker_init_fn\n",
    "from ca_body.utils.torchutils import to_device\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "\n",
    "device = th.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '../config/mesh_vae_example.yml'\n",
    "config = OmegaConf.load(config_path)\n",
    "config.root_dir = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf2480",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(f\"cuda:0\")\n",
    "\n",
    "train_dataset = BodyDataset(**config.data)\n",
    "static_assets = AttrDict(train_dataset.static_assets)\n",
    "\n",
    "model = load_from_config(config.model, assets=static_assets).to(device)\n",
    "optimizer = build_optimizer(config.optimizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_Rt = th.as_tensor(static_assets.floor_Rt, device=device)\n",
    "floor_Rt_inv = th.as_tensor(static_assets.floor_Rt_inv, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    **config.dataloader,\n",
    "    worker_init_fn=worker_init_fn,\n",
    ")\n",
    "\n",
    "batch = to_device(next(iter(train_loader)), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d44cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cal_enabled = False\n",
    "model.learn_blur_enabled = False\n",
    "model.pixel_cal_enabled = False\n",
    "model.rendering_enabled = True\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f583a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rendering(cam_x=0, cam_y=1000, cam_z=3000, angle_X=0, angle_Y=-0.91, fidx=0):\n",
    "    \n",
    "    angle_Z = -3.14\n",
    "\n",
    "    B = batch['pose'].shape[0]\n",
    "    # TODO: should we be able to switch this?\n",
    "    K = to_device(batch['K'][fidx:fidx+1], device)\n",
    "    pose = to_device(batch['pose'][fidx:fidx+1], device)\n",
    "    \n",
    "    floor_R, floor_t = floor_Rt[:3, :3], floor_Rt[:3, 3]\n",
    "\n",
    "    ambient_occlusion = to_device(batch['ambient_occlusion'][fidx:fidx+1], device)\n",
    "    registration_vertices = to_device(batch['registration_vertices'][fidx:fidx+1], device)\n",
    "\n",
    "    XYZ = th.as_tensor([angle_X, angle_Y, angle_Z], dtype=th.float32, device=device)[np.newaxis].expand(1, -1)\n",
    "    R = EulerXYZ_to_matrix(XYZ)\n",
    "    Rt = th.eye(3, 4, device=device)[np.newaxis].expand(1, -1, -1).clone()\n",
    "    # NOTE: we are rotating around the model space!\n",
    "    Rt[:,:3,:3] = R\n",
    "    Rt[:,0,3] = cam_x\n",
    "    Rt[:,1,3] = cam_y\n",
    "    Rt[:,2,3] = cam_z\n",
    "\n",
    "    np_Rt = Rt[0].cpu().numpy()\n",
    "    XYZ_str = np.array2string(XYZ[0].cpu().numpy(), formatter={'float_kind':lambda x: \"%.3f\" % x}, separator=',')\n",
    "    cam_xyz_str = np.array2string(Rt[0,:3,3].cpu().numpy(), formatter={'float_kind':lambda x: \"%.0f\" % x}, separator=',')\n",
    "\n",
    "    frame_id_str = str(int(batch['frame_id'][fidx]))\n",
    "    params_text.value = f'XYZ = {XYZ_str} \\ncam_xyz = {cam_xyz_str}\\nframe = {frame_id_str}'\n",
    "\n",
    "    with th.no_grad():\n",
    "        floor_R_inv, floor_t_inv = floor_Rt_inv[:3, :3], floor_Rt_inv[:3, 3]\n",
    "        \n",
    "        campos = (th.bmm(Rt[:, :3,:3].permute(0, 2, 1), -Rt[:, :3, 3:])[...,0]).to(th.float32)\n",
    "        campos = ((floor_R_inv @ campos.to(th.float64).T).T + floor_t_inv).to(th.float32)        \n",
    "        \n",
    "        preds = model(\n",
    "            pose=pose,\n",
    "            registration_vertices=registration_vertices,\n",
    "            ambient_occlusion=ambient_occlusion,\n",
    "            campos=campos,\n",
    "            K=K,\n",
    "            Rt=Rt,\n",
    "        )    \n",
    "\n",
    "        geom = preds['geom']\n",
    "        tex_rec = preds[\"tex_rec\"]\n",
    "\n",
    "        # transform to socio space\n",
    "        geom = (th.matmul(geom.to(th.float64), floor_R.T[np.newaxis]) + floor_t).to(th.float32)\n",
    "\n",
    "        # rendering avatar\n",
    "        renders = model.renderer(\n",
    "            geom,\n",
    "            tex_rec,\n",
    "            K=K,\n",
    "            Rt=Rt,\n",
    "        )    \n",
    "\n",
    "        np_image = linear2displayBatch(renders['render']).permute(0, 2, 3, 1)[0].cpu().numpy()\n",
    "        canvas.put_image_data(np_image)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b853e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipycanvas import Canvas\n",
    "from ipywidgets import VBox, HBox, interactive, Output, Textarea\n",
    "\n",
    "params_text = Textarea(width=1000)\n",
    "\n",
    "canvas = Canvas(width=model.renderer.w, height=model.renderer.h)\n",
    "\n",
    "B = batch[\"pose\"].shape[0]\n",
    "\n",
    "controls = interactive(\n",
    "    update_rendering, \n",
    "    cam_z=(-5000, 3000, 5), \n",
    "    cam_y=(-2000, 3000, 5),\n",
    "    cam_x=(-3000, 3000, 5),     \n",
    "    angle_X=(-np.pi, np.pi, (np.pi / 180.0) * 1.0),\n",
    "    angle_Y=(-2 * np.pi, 2 * np.pi, (np.pi / 180.0) * 1.0),    \n",
    "    fidx=(0, B-1),\n",
    ")\n",
    "# TODO: add rendering?\n",
    "from ipywidgets import HBox, Label\n",
    "style = {\"description_width\": \"initial\"}\n",
    "from ipywidgets import IntSlider\n",
    "\n",
    "HBox([canvas, VBox([controls, params_text])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
